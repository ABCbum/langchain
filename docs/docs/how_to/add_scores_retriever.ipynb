{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d59582a-6473-4b34-929b-3e94cb443c3d",
   "metadata": {},
   "source": [
    "# How to add scores to retriever results\n",
    "\n",
    "Retrievers will return sequences of [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, which by default include no information about the process that retrieved them (e.g., a similarity score against a query). Here we demonstrate how to add retrieval scores to the `.metadata` of documents:\n",
    "1. From [vectorstore retrievers](/docs/how_to/vectorstore_retriever);\n",
    "2. From higher-order LangChain retrievers, such as [SelfQueryRetriever](/docs/how_to/self_query) or [MultiVectorRetriever](/docs/how_to/multi_vector).\n",
    "\n",
    "For (1), we will implement a short wrapper function around the corresponding vector store. For (2), we will update a method of the corresponding class.\n",
    "\n",
    "## Create vector store\n",
    "\n",
    "First we populate a vector store with some data. We will use a [PineconeVectorStore](https://python.langchain.com/v0.2/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html), but this guide is compatible with any LangChain vector store that implements a `.similarity_search_with_score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cfcb1b-64ee-4b91-8d82-ce7803834985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:50.687612Z",
     "iopub.status.busy": "2024-09-11T18:05:50.687225Z",
     "iopub.status.idle": "2024-09-11T18:05:51.324675Z",
     "shell.execute_reply": "2024-09-11T18:05:51.324351Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_pinecone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_pinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PineconeVectorStore\n\u001b[1;32m      5\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     Document(\n\u001b[1;32m      7\u001b[0m         page_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA bunch of scientists bring back dinosaurs and mayhem breaks loose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     ),\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m PineconeVectorStore\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[1;32m     38\u001b[0m     docs, index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding\u001b[38;5;241m=\u001b[39mOpenAIEmbeddings()\n\u001b[1;32m     39\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_pinecone'"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    docs, index_name=\"sample\", embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac5ef6-ce18-427f-a91c-62b38a8b41e9",
   "metadata": {},
   "source": [
    "## Retriever\n",
    "\n",
    "To obtain scores from a vector store retriever, we wrap the underlying vector store's `.similarity_search_with_score` method in a short function that packages scores into the associated document's metadata.\n",
    "\n",
    "We add a `@chain` decorator to the function to create a [Runnable](/docs/concepts/#langchain-expression-language) that can be used similarly to a typical retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5677c3-f6ee-4974-ab5f-a0f50c199d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.326192Z",
     "iopub.status.busy": "2024-09-11T18:05:51.326095Z",
     "iopub.status.idle": "2024-09-11T18:05:51.328297Z",
     "shell.execute_reply": "2024-09-11T18:05:51.328011Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*vectorstore.similarity_search_with_score(query))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"score\"] = score\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cad75e-b955-4012-989c-3c1820b49ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.329636Z",
     "iopub.status.busy": "2024-09-11T18:05:51.329553Z",
     "iopub.status.idle": "2024-09-11T18:05:51.476132Z",
     "shell.execute_reply": "2024-09-11T18:05:51.475851Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdinosaur\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m result\n",
      "File \u001b[0;32m~/langchain/libs/core/langchain_core/runnables/base.py:4680\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4666\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4667\u001b[0m \n\u001b[1;32m   4668\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4677\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4678\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4681\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4682\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4683\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4684\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4689\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4690\u001b[0m     )\n",
      "File \u001b[0;32m~/langchain/libs/core/langchain_core/runnables/base.py:1915\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1912\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1913\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1914\u001b[0m         Output,\n\u001b[0;32m-> 1915\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1918\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1919\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1923\u001b[0m     )\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1925\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/langchain/libs/core/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/langchain/libs/core/langchain_core/runnables/base.py:4536\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4534\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4536\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4537\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4538\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4539\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/langchain/libs/core/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mretriever\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@chain\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretriever\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m----> 9\u001b[0m     docs, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(query))\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(docs, scores):\n\u001b[1;32m     11\u001b[0m         doc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "result = retriever.invoke(\"dinosaur\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671308a-be8d-4c15-ae1f-5bd07b342560",
   "metadata": {},
   "source": [
    "Note that similarity scores from the retrieval step are included in the metadata of the above documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e73a0-46a1-47e2-8103-68aaa637642a",
   "metadata": {},
   "source": [
    "## SelfQueryRetriever\n",
    "\n",
    "`SelfQueryRetriever` will use a LLM to generate a query that is potentially structured-- for example, it can construct filters for the retrieval on top of the usual semantic-similarity driven selection. See [this guide](/docs/how_to/self_query) for more detail.\n",
    "\n",
    "`SelfQueryRetriever` includes a short (1 - 2 line) method `_get_docs_with_query` that executes the `vectorstore` search. We can subclass `SelfQueryRetriever` and override this method to propagate similarity scores.\n",
    "\n",
    "First, following the [how-to guide](/docs/how_to/self_query), we will need to establish some metadata on which to filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8280b829-2e81-4454-8adc-9a0930047fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.478185Z",
     "iopub.status.busy": "2024-09-11T18:05:51.478040Z",
     "iopub.status.idle": "2024-09-11T18:05:51.653158Z",
     "shell.execute_reply": "2024-09-11T18:05:51.645646Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c6fa8-1e2f-45ee-83e9-a6cbd82292d2",
   "metadata": {},
   "source": [
    "We then override the `_get_docs_with_query` to use the `similarity_search_with_score` method of the underlying vector store: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c8f3fa-8b64-4afb-87c4-ccbbf9a8bc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.663405Z",
     "iopub.status.busy": "2024-09-11T18:05:51.662121Z",
     "iopub.status.idle": "2024-09-11T18:05:51.678590Z",
     "shell.execute_reply": "2024-09-11T18:05:51.674622Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "class CustomSelfQueryRetriever(SelfQueryRetriever):\n",
    "    def _get_docs_with_query(\n",
    "        self, query: str, search_kwargs: Dict[str, Any]\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Get docs, adding score information.\"\"\"\n",
    "        docs, scores = zip(\n",
    "            *vectorstore.similarity_search_with_score(query, **search_kwargs)\n",
    "        )\n",
    "        for doc, score in zip(docs, scores):\n",
    "            doc.metadata[\"score\"] = score\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e40109-1db6-44c7-a6e6-6989175e267c",
   "metadata": {},
   "source": [
    "Invoking this retriever will now include similarity scores in the document metadata. Note that the underlying structured-query capabilities of `SelfQueryRetriever` are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3359a1ee-34ff-41b6-bded-64c05785b333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.695075Z",
     "iopub.status.busy": "2024-09-11T18:05:51.694645Z",
     "iopub.status.idle": "2024-09-11T18:05:51.744720Z",
     "shell.execute_reply": "2024-09-11T18:05:51.741452Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m CustomSelfQueryRetriever\u001b[38;5;241m.\u001b[39mfrom_llm(\n\u001b[1;32m      2\u001b[0m     llm,\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mvectorstore\u001b[49m,\n\u001b[1;32m      4\u001b[0m     document_content_description,\n\u001b[1;32m      5\u001b[0m     metadata_field_info,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdinosaur movie with rating less than 8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m result\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "retriever = CustomSelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "\n",
    "\n",
    "result = retriever.invoke(\"dinosaur movie with rating less than 8\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ab3ba-3494-448b-836e-05fbe1ffd51c",
   "metadata": {},
   "source": [
    "## MultiVectorRetriever\n",
    "\n",
    "`MultiVectorRetriever` allows you to associate multiple vectors with a single document. This can be useful in a number of applications. For example, we can index small chunks of a larger document and run the retrieval on the chunks, but return the larger \"parent\" document when invoking the retriever. [ParentDocumentRetriever](/docs/how_to/parent_document_retriever/), a subclass of `MultiVectorRetriever`, includes convenience methods for populating a vector store to support this. Further applications are detailed in this [how-to guide](/docs/how_to/multi_vector/).\n",
    "\n",
    "To propagate similarity scores through this retriever, we can again subclass `MultiVectorRetriever` and override a method. This time we will override `_get_relevant_documents`.\n",
    "\n",
    "First, we prepare some fake data. We generate fake \"whole documents\" and store them in a document store; here we will use a simple [InMemoryStore](https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.InMemoryBaseStore.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a112e545-7b53-4fcd-9c4a-7a42a5cc646d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.753226Z",
     "iopub.status.busy": "2024-09-11T18:05:51.752489Z",
     "iopub.status.idle": "2024-09-11T18:05:51.761297Z",
     "shell.execute_reply": "2024-09-11T18:05:51.760065Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "docstore = InMemoryStore()\n",
    "fake_whole_documents = [\n",
    "    (\"fake_id_1\", Document(page_content=\"fake whole document 1\")),\n",
    "    (\"fake_id_2\", Document(page_content=\"fake whole document 2\")),\n",
    "]\n",
    "docstore.mset(fake_whole_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b7415-4a6d-45d4-a329-9c1d7271d1b2",
   "metadata": {},
   "source": [
    "Next we will add some fake \"sub-documents\" to our vector store. We can link these sub-documents to the parent documents by populating the `\"doc_id\"` key in its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314519c0-dde4-41ea-a1ab-d3cf1c17c63f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.770350Z",
     "iopub.status.busy": "2024-09-11T18:05:51.770027Z",
     "iopub.status.idle": "2024-09-11T18:05:51.798827Z",
     "shell.execute_reply": "2024-09-11T18:05:51.798534Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     Document(\n\u001b[1;32m      3\u001b[0m         page_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA snippet from a larger document discussing cats.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     ),\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 16\u001b[0m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39madd_documents(docs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A snippet from a larger document discussing cats.\",\n",
    "        metadata={\"doc_id\": \"fake_id_1\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A snippet from a larger document discussing discourse.\",\n",
    "        metadata={\"doc_id\": \"fake_id_1\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A snippet from a larger document discussing chocolate.\",\n",
    "        metadata={\"doc_id\": \"fake_id_2\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "vectorstore.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391f7f3-5a58-40fd-89fa-a0815c5146f7",
   "metadata": {},
   "source": [
    "To propagate the scores, we subclass `MultiVectorRetriever` and override its `_get_relevant_documents` method. Here we will make two changes:\n",
    "\n",
    "1. We will add similarity scores to the metadata of the corresponding \"sub-documents\" using the `similarity_search_with_score` method of the underlying vector store as above;\n",
    "2. We will include a list of these sub-documents in the metadata of the retrieved parent document. This surfaces what snippets of text were identified by the retrieval, together with their corresponding similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de61de7-1b58-41d6-9dea-939fef7d741d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.800495Z",
     "iopub.status.busy": "2024-09-11T18:05:51.800386Z",
     "iopub.status.idle": "2024-09-11T18:05:51.805285Z",
     "shell.execute_reply": "2024-09-11T18:05:51.805012Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "\n",
    "\n",
    "class CustomMultiVectorRetriever(MultiVectorRetriever):\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Get documents relevant to a query.\n",
    "        Args:\n",
    "            query: String to find relevant documents for\n",
    "            run_manager: The callbacks handler to use\n",
    "        Returns:\n",
    "            List of relevant documents\n",
    "        \"\"\"\n",
    "        results = self.vectorstore.similarity_search_with_score(\n",
    "            query, **self.search_kwargs\n",
    "        )\n",
    "\n",
    "        # Map doc_ids to list of sub-documents, adding scores to metadata\n",
    "        id_to_doc = defaultdict(list)\n",
    "        for doc, score in results:\n",
    "            doc_id = doc.metadata.get(\"doc_id\")\n",
    "            if doc_id:\n",
    "                doc.metadata[\"score\"] = score\n",
    "                id_to_doc[doc_id].append(doc)\n",
    "\n",
    "        # Fetch documents corresponding to doc_ids, retaining sub_docs in metadata\n",
    "        docs = []\n",
    "        for _id, sub_docs in id_to_doc.items():\n",
    "            docstore_docs = self.docstore.mget([_id])\n",
    "            if docstore_docs:\n",
    "                if doc := docstore_docs[0]:\n",
    "                    doc.metadata[\"sub_docs\"] = sub_docs\n",
    "                    docs.append(doc)\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af27b38-631c-463f-9d66-bcc985f06a4f",
   "metadata": {},
   "source": [
    "Invoking this retriever, we can see that it identifies the correct parent document, including the relevant snippet from the sub-document with similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc42a1be-22e1-4ade-b1bd-bafb85f2424f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:05:51.806605Z",
     "iopub.status.busy": "2024-09-11T18:05:51.806523Z",
     "iopub.status.idle": "2024-09-11T18:05:51.815132Z",
     "shell.execute_reply": "2024-09-11T18:05:51.814917Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m CustomMultiVectorRetriever(vectorstore\u001b[38;5;241m=\u001b[39m\u001b[43mvectorstore\u001b[49m, docstore\u001b[38;5;241m=\u001b[39mdocstore)\n\u001b[1;32m      3\u001b[0m retriever\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "retriever = CustomMultiVectorRetriever(vectorstore=vectorstore, docstore=docstore)\n",
    "\n",
    "retriever.invoke(\"cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
