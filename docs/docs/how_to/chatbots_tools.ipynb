{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to add tools to chatbots\n",
    "\n",
    ":::info Prerequisites\n",
    "\n",
    "This guide assumes familiarity with the following concepts:\n",
    "\n",
    "- [Chatbots](/docs/concepts/#messages)\n",
    "- [Agents](/docs/tutorials/agents)\n",
    "- [Chat history](/docs/concepts/#chat-history)\n",
    "\n",
    ":::\n",
    "\n",
    "This section will cover how to create conversational agents: chatbots that can interact with other systems and APIs using tools.\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this guide, we'll be using a [tool calling agent](/docs/how_to/agent_executor) with a single tool for searching the web. The default will be powered by [Tavily](/docs/integrations/tools/tavily_search), but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\n",
    "\n",
    "You'll need to [sign up for an account](https://tavily.com/) on the Tavily website, and install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:12.678158Z",
     "iopub.status.busy": "2024-09-11T18:10:12.677757Z",
     "iopub.status.idle": "2024-09-11T18:10:16.440326Z",
     "shell.execute_reply": "2024-09-11T18:10:16.439828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langchain-benchmarks 0.0.14 requires langchain<0.3.0,>=0.2.7, but you have langchain 0.3.0.dev1 which is incompatible.\r\n",
      "langchain-benchmarks 0.0.14 requires langchain-community<0.3,>=0.2, but you have langchain-community 0.3.0.dev1 which is incompatible.\r\n",
      "langchain-benchmarks 0.0.14 requires langchain-openai<0.2.0,>=0.1.14, but you have langchain-openai 0.2.0.dev2 which is incompatible.\r\n",
      "langchain-aws 0.1.15 requires langchain-core<0.3,>=0.2.29, but you have langchain-core 0.3.0.dev4 which is incompatible.\r\n",
      "langchain-chroma 0.1.3 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.0.dev4 which is incompatible.\r\n",
      "langchain-together 0.1.5 requires langchain-core<0.3.0,>=0.2.26, but you have langchain-core 0.3.0.dev4 which is incompatible.\r\n",
      "langchain-together 0.1.5 requires langchain-openai<0.2.0,>=0.1.16, but you have langchain-openai 0.2.0.dev2 which is incompatible.\r\n",
      "langserve 0.2.2 requires langchain-core<0.3,>=0.1, but you have langchain-core 0.3.0.dev4 which is incompatible.\r\n",
      "langchain-standard-tests 0.1.1 requires langchain-core<0.3,>=0.1.40, but you have langchain-core 0.3.0.dev4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\n",
    "\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need your OpenAI key set as `OPENAI_API_KEY` and your Tavily API key set as `TAVILY_API_KEY`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an agent\n",
    "\n",
    "Our end goal is to create an agent that can respond conversationally to user questions while looking up information as needed.\n",
    "\n",
    "First, let's initialize Tavily and an OpenAI chat model capable of tool calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:16.443339Z",
     "iopub.status.busy": "2024-09-11T18:10:16.443080Z",
     "iopub.status.idle": "2024-09-11T18:10:16.946587Z",
     "shell.execute_reply": "2024-09-11T18:10:16.946264Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "# Only certain models support this\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our agent conversational, we must also choose a prompt with a placeholder for our chat history. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:16.948280Z",
     "iopub.status.busy": "2024-09-11T18:10:16.948157Z",
     "iopub.status.idle": "2024-09-11T18:10:16.950266Z",
     "shell.execute_reply": "2024-09-11T18:10:16.949973Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Adapted from https://smith.langchain.com/hub/jacob/tool-calling-agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's assemble our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:16.951693Z",
     "iopub.status.busy": "2024-09-11T18:10:16.951609Z",
     "iopub.status.idle": "2024-09-11T18:10:17.294367Z",
     "shell.execute_reply": "2024-09-11T18:10:17.290630Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the agent\n",
    "\n",
    "Now that we've set up our agent, let's try interacting with it! It can handle both trivial queries that require no lookup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:17.311675Z",
     "iopub.status.busy": "2024-09-11T18:10:17.311017Z",
     "iopub.status.idle": "2024-09-11T18:10:18.649004Z",
     "shell.execute_reply": "2024-09-11T18:10:18.648536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHi Nemo! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Hi Nemo! How can I assist you today?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"I'm Nemo!\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, it can use of the passed search tool to get up to date information if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:18.652056Z",
     "iopub.status.busy": "2024-09-11T18:10:18.651859Z",
     "iopub.status.idle": "2024-09-11T18:10:24.989761Z",
     "shell.execute_reply": "2024-09-11T18:10:24.989147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current conservation status of the Great Barrier Reef 2023'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[{'url': 'https://www.dcceew.gov.au/sites/default/files/documents/great-barrier-reef-progress-report-2024.pdf', 'content': 'Reports on the State of Conservation (December 2019, February 2022), additional information ... UNESCO in May 2023 on the Great Barrier Reef (the Reef) World Heritage Area (available online at: www .dcceew .gov .au/parks-heritage/ ... Status: Complete WQ2.By 31 December 2023: Initiate the delivery of a joint federal-state'}]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe current conservation status of the Great Barrier Reef is a topic of ongoing concern, particularly due to its classification as a World Heritage site. Recent reports indicate that the reef is facing significant challenges, including climate change, coral bleaching, and water quality issues.\n",
      "\n",
      "For the most detailed and up-to-date information, you can refer to the [Great Barrier Reef Progress Report 2024](https://www.dcceew.gov.au/sites/default/files/documents/great-barrier-reef-progress-report-2024.pdf), which includes insights from various assessments and initiatives aimed at improving the reef's health and resilience. \n",
      "\n",
      "If you have specific aspects of the conservation status you're interested in, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current conservation status of the Great Barrier Reef?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': \"The current conservation status of the Great Barrier Reef is a topic of ongoing concern, particularly due to its classification as a World Heritage site. Recent reports indicate that the reef is facing significant challenges, including climate change, coral bleaching, and water quality issues.\\n\\nFor the most detailed and up-to-date information, you can refer to the [Great Barrier Reef Progress Report 2024](https://www.dcceew.gov.au/sites/default/files/documents/great-barrier-reef-progress-report-2024.pdf), which includes insights from various assessments and initiatives aimed at improving the reef's health and resilience. \\n\\nIf you have specific aspects of the conservation status you're interested in, feel free to ask!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"What is the current conservation status of the Great Barrier Reef?\"\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational responses\n",
    "\n",
    "Because our prompt contains a placeholder for chat history messages, our agent can also take previous interactions into account and respond conversationally like a standard chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:24.993130Z",
     "iopub.status.busy": "2024-09-11T18:10:24.992855Z",
     "iopub.status.idle": "2024-09-11T18:10:25.537198Z",
     "shell.execute_reply": "2024-09-11T18:10:25.536654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mYour name is Nemo!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello Nemo! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Nemo!'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I'm Nemo!\"),\n",
    "            AIMessage(content=\"Hello Nemo! How can I assist you today?\"),\n",
    "            HumanMessage(content=\"What is my name?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If preferred, you can also wrap the agent executor in a [`RunnableWithMessageHistory`](/docs/how_to/message_history/) class to internally manage history messages. Let's redeclare it this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:25.540264Z",
     "iopub.status.busy": "2024-09-11T18:10:25.540028Z",
     "iopub.status.idle": "2024-09-11T18:10:25.547961Z",
     "shell.execute_reply": "2024-09-11T18:10:25.545677Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because our agent executor has multiple outputs, we also have to set the `output_messages_key` property when initializing the wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:25.551591Z",
     "iopub.status.busy": "2024-09-11T18:10:25.551325Z",
     "iopub.status.idle": "2024-09-11T18:10:26.710516Z",
     "shell.execute_reply": "2024-09-11T18:10:26.709806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHi Nemo! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\", additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Hi Nemo! How can I assist you today?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history_for_chain = ChatMessageHistory()\n",
    "\n",
    "conversational_agent_executor = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: demo_ephemeral_chat_history_for_chain,\n",
    "    input_messages_key=\"messages\",\n",
    "    output_messages_key=\"output\",\n",
    ")\n",
    "\n",
    "conversational_agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(\"I'm Nemo!\")]},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then if we rerun our wrapped agent executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T18:10:26.714862Z",
     "iopub.status.busy": "2024-09-11T18:10:26.714472Z",
     "iopub.status.idle": "2024-09-11T18:10:27.526499Z",
     "shell.execute_reply": "2024-09-11T18:10:27.526006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mYour name is Nemo!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hi Nemo! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Nemo!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(\"What is my name?\")]},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [LangSmith trace](https://smith.langchain.com/public/1a9f712a-7918-4661-b3ff-d979bcc2af42/r) shows what's going on under the hood.\n",
    "\n",
    "## Further reading\n",
    "\n",
    "Other types agents can also support conversational responses too - for more, check out the [agents section](/docs/tutorials/agents).\n",
    "\n",
    "For more on tool usage, you can also check out [this use case section](/docs/how_to#tools)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
