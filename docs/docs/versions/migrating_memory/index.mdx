---
sidebar_position: 1
---

# How to migrate from v0.0 memory

The concept of memory has evolved significantly in LangChain since its initial release.

Broadly speaking, LangChain 0.0.x memory was used to handle four main use cases:

1. Managing conversation history. For example, keep only the last `n` turns of the conversation between the user and the AI. See Migration guide for this use case is available [here](./manage_conversation_history).
2. Extraction of structured information from the conversation history and providing it as context. For example, extract a list of facts learned about a user during the conversation.
3. Implementations that provide composite logic on top of one or more memory implementations. For example, a memory implementation that combines a list of known facts about a user together with a list of facts learned during a given conversation.
4. Custom user code based on the memory interface.

While the LangChain 0.0.x memory abstractions were useful, they were limited in their capabilities and not well suited for real-world conversational AI applications. Many of these abstractions were written before the existence of chat models and do not work well with chat models. In addition,
they did not provide a good way to handle multi-user, multi-conversation scenarios, which are often a requirement for real-world conversational AI applications.

This guide will help you migrate your usage of memory implementations from LangChain v0.0.x to the persistence implementations of LangGraph.

Where possible we may show an equivalent implementation using just [LCEL](/docs/concepts/#langchain-expression-language-lcel)
without LangGraph; however, in general, we recommend that users swap to using LangGraph for most use cases.

## Advantages of LangGraph persistence

The main advantages of persistence implementation in LangGraph are:

- Built-in support for multi-user, multi-conversation scenarios which is often a requirement for real-world conversational AI applications.
- Ability to save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more.
- Full support for both LLM and chat models. In contrast, the v0.0.x memory abstractions were created prior to the existence and widespread adoption of chat model APIs, and so it does not work well with chat models (e.g., fails with tool calling chat models).
- Offers a high degree of customization and control over the memory implementation, including the ability to use different backend.

## Migrations

:::info Prerequisites

These guides assume some familiarity with the following concepts:
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [v0.0.x Memory](https://python.langchain.com/v0.1/docs/modules/memory/)
- [How to add persistence ("memory") to your graph](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
:::

### 1. Managing conversation history

The goal of managing conversation history is to store and retrieve the history in a way that is optimal for a chat model to use.

Often this involves trimming and / or summarizing the conversation history to keep the most relevant parts of the conversation
while having the conversation fit inside the context window of the chat model.

Please follow [this guide](./manage_conversation_history) to see how to migrate to modern LangChain and LangGraph primitives for managing conversation history.

There are different strategies for managing conversation history. The following memory classes in LangChain v0.0.x fall into this category:

| Memory Type                       | Description                                                                                                                                                                                                         |
|-----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `ConversationBufferMemory`        | A basic memory implementation that simply stores the conversation history.                                                                                                                                          |
| `ConversationStringBufferMemory`  | A special case of `ConversationBufferMemory` designed for LLMs and no longer relevant.                                                                                                                              |
| `ConversationBufferWindowMemory`  | Keeps the last `n` turns of the conversation. Drops the oldest turn when the buffer is full.                                                                                                                        |
| `ConversationTokenBufferMemory`   | Keeps only the most recent messages in the conversation under the constraint that the total number of tokens in the conversation does not exceed a certain limit.                                                   |
| `ConversationSummaryMemory`       | Continually summarizes the conversation history. The summary is updated after each conversation turn. The abstraction returns the summary of the conversation history.                                              |
| `ConversationSummaryBufferMemory` | Provides a running summary of the conversation together with the most recent messages in the conversation under the constraint that the total number of tokens in the conversation does not exceed a certain limit. |
| `VectorStoreRetrieverMemory`      | Stores the conversation history in a vector store and retrieves the most relevant parts of past conversation based on the input.                                                                                    |

### 2. Extraction of structured information from the conversation history

We do not currently have a guide for this. If you need help with migrating these, please
open an issue in the docs, and we'll try to prioritize and write migration guidelines.

The general strategy should be to use a chat model with tool calling capabilities to extract structured information from the conversation history.
The extracted information can then be saved into an appropriate data structure (e.g., a dictionary), and information from it can be retrieved and added
into the prompt when needed.

Memory classes that fall into this category include:

| Memory Type                | Description                                                                                                                                                                                                       |
|----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `BaseEntityStore`          | An abstract interface that resembles a key-value store. It was used for storing structured information learned during the conversation. The information had to be represented as a dictionary of key-value pairs. |
| `ConversationEntityMemory` | Combines the ability to summarize the conversation while extracting structured information from the conversation history.                                                                                         |

And specific backend implementations of abstractions:

| Memory Type               | Description                                                                                              |
|---------------------------|----------------------------------------------------------------------------------------------------------|
| `InMemoryEntityStore`     | An implementation of `BaseEntityStore` that stores the information in the literal computer memory (RAM). |
| `RedisEntityStore`        | A specific implementation of `BaseEntityStore` that uses Redis as the backend.                           |
| `SQLiteEntityStore`       | A specific implementation of `BaseEntityStore` that uses SQLite as the backend.                          |
| `UpstashRedisEntityStore` | A specific implementation of `BaseEntityStore` that uses Upstash as the backend.                         |

### 3. Implementations that provide composite logic on top of one or more memory implementations

Memory classes that fall into this category include:

| Memory Type            | Description                                                                                                                    |
|------------------------|--------------------------------------------------------------------------------------------------------------------------------|
| `CombinedMemory`       | This abstraction accepted a list of `BaseMemory` and fetched relevant memory information from each of them based on the input. |
| `SimpleMemory`         | Used to add read-only hard-coded context. Users can simply write this information into the prompt.                             |
| `ReadOnlySharedMemory` | Provided a read-only view of an existing `BaseMemory` implementation.                                                          |

### 4. Custom user code based on the memory interface

If you have custom code that subclasses from `BaseMemory`, `BaseChatMemory`, or `BaseEntityStore`, you will need to re-implement the code using the appropriate primitives. Often, this involves lightweight processing of the conversation history, such as filtering or summarization.

Alternatively, you could use the existing implementations using the `load_memory_variables` and `save_context` API directly and write the appropriate glue code for your use case.

## Related Resources

Explore persistence with LangGraph:

* [LangGraph quickstart tutorial](https://langchain-ai.github.io/langgraph/tutorials/introduction/)
* [How to add persistence ("memory") to your graph](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
* [How to manage conversation history](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/)
* [How to add summary of the conversation history](https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/)

Add persistence with simple LCEL (favor langgraph for more complex use cases):

* [How to add message history](https://python.langchain.com/docs/how_to/message_history/)

Working with message history:

* [How to trim messages](https://python.langchain.com/docs/how_to/trim_messages)
* [How to filter messages](https://python.langchain.com/docs/how_to/filter_messages/)
* [How to merge message runs](https://python.langchain.com/docs/how_to/merge_message_runs/)
